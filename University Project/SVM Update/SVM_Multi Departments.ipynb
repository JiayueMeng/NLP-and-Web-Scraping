{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b8e1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from math import log\n",
    "import random\n",
    "from random import randint\n",
    "import numpy as np \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras\n",
    "import warnings\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56943231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the result for testing between Physics, History, and Computer Science apartment of four colleges\n",
    "#UR, UB, VAN, MIT\n",
    "#The dataset has a total size of 610,\n",
    "#while 118 is form History, 270 is from Physics, 222 is from Computer Sciecne.\n",
    "#We chose 20 words that matters the most to form the dataset, \n",
    "#and label data from History as \"1\", data from Physics as \"2\", and data from Computer Science as \"3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b0cfaa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research</th>\n",
       "      <th>engineering</th>\n",
       "      <th>studies</th>\n",
       "      <th>science</th>\n",
       "      <th>film</th>\n",
       "      <th>seluanov</th>\n",
       "      <th>gorbunova</th>\n",
       "      <th>spin</th>\n",
       "      <th>journal</th>\n",
       "      <th>literature</th>\n",
       "      <th>...</th>\n",
       "      <th>mobile</th>\n",
       "      <th>prize</th>\n",
       "      <th>area</th>\n",
       "      <th>feedback</th>\n",
       "      <th>processes</th>\n",
       "      <th>huo</th>\n",
       "      <th>lett</th>\n",
       "      <th>ocean</th>\n",
       "      <th>mitchell</th>\n",
       "      <th>mitra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133825</td>\n",
       "      <td>6.091850</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.703516</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.141654</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.453708</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.036506</td>\n",
       "      <td>6.886457</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.126570</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.549105</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.429008</td>\n",
       "      <td>2.265932</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.517546</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.76942</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814299</td>\n",
       "      <td>5.963042</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>6.416940</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.787349</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>8.066240</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.030624</td>\n",
       "      <td>33.120246</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.043467</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2.486010</td>\n",
       "      <td>-0.050947</td>\n",
       "      <td>6.509896</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>11.661846</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6.988950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>-0.015155</td>\n",
       "      <td>-0.008282</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.906729</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.226845</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>-0.015159</td>\n",
       "      <td>-0.008294</td>\n",
       "      <td>5.454643</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.922337</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.940224</td>\n",
       "      <td>90.434222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>-0.084800</td>\n",
       "      <td>-0.046450</td>\n",
       "      <td>5.140450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>19.785706</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.402575</td>\n",
       "      <td>1.435222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>3.732752</td>\n",
       "      <td>-0.012862</td>\n",
       "      <td>5.847669</td>\n",
       "      <td>1.487289</td>\n",
       "      <td>9.352954</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.530372</td>\n",
       "      <td>95.544805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     research  engineering   studies   science       film  seluanov  \\\n",
       "0    0.133825     6.091850 -0.000000  0.083916   1.703516      -0.0   \n",
       "1   -0.036506     6.886457 -0.000000 -0.126570  -0.000000      -0.0   \n",
       "2    2.429008     2.265932 -0.000000 -0.000000   0.517546      -0.0   \n",
       "3   -0.814299     5.963042 -0.000000 -0.000000  -0.000000      -0.0   \n",
       "4   -1.030624    33.120246 -0.000000 -0.000000  -0.000000      -0.0   \n",
       "..        ...          ...       ...       ...        ...       ...   \n",
       "617  2.486010    -0.050947  6.509896 -0.000000  11.661846      -0.0   \n",
       "618 -0.015155    -0.008282 -0.000000 -0.000000   1.906729      -0.0   \n",
       "619 -0.015159    -0.008294  5.454643 -0.000000   1.922337      -0.0   \n",
       "620 -0.084800    -0.046450  5.140450 -0.000000  19.785706      -0.0   \n",
       "621  3.732752    -0.012862  5.847669  1.487289   9.352954      -0.0   \n",
       "\n",
       "     gorbunova  spin   journal  literature  ...  mobile  prize      area  \\\n",
       "0         -0.0  -0.0  0.141654   -0.000000  ...    -0.0   -0.0 -0.000000   \n",
       "1         -0.0  -0.0  3.549105   -0.000000  ...    -0.0   -0.0 -0.000000   \n",
       "2         -0.0  -0.0 -0.000000   -0.000000  ...    -0.0   -0.0 -0.000000   \n",
       "3         -0.0  -0.0  6.416940   -0.000000  ...    -0.0   -0.0  0.787349   \n",
       "4         -0.0  -0.0  3.043467   -0.000000  ...    -0.0   -0.0 -0.000000   \n",
       "..         ...   ...       ...         ...  ...     ...    ...       ...   \n",
       "617       -0.0  -0.0 -0.000000    6.988950  ...    -0.0   -0.0 -0.000000   \n",
       "618       -0.0  -0.0 -0.000000   -0.000000  ...    -0.0   -0.0 -0.000000   \n",
       "619       -0.0  -0.0  1.940224   90.434222  ...    -0.0   -0.0 -0.000000   \n",
       "620       -0.0  -0.0  1.402575    1.435222  ...    -0.0   -0.0 -0.000000   \n",
       "621       -0.0  -0.0  1.530372   95.544805  ...    -0.0   -0.0 -0.000000   \n",
       "\n",
       "     feedback  processes  huo     lett  ocean  mitchell  mitra  \n",
       "0   -0.000000   0.453708 -0.0 -0.00000   -0.0  0.008231   -0.0  \n",
       "1   -0.000000  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "2   -0.000000  -0.000000 -0.0  0.76942   -0.0 -0.000000   -0.0  \n",
       "3   -0.000000   8.066240 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "4   -0.000000  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "..        ...        ...  ...      ...    ...       ...    ...  \n",
       "617 -0.000000  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "618  0.226845  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "619 -0.000000  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "620 -0.000000  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "621 -0.000000  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0  \n",
       "\n",
       "[622 rows x 200 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the part to do some basic process about the dataset. For the firt 118 rows, which is the data from history,\n",
    "#add in a label \"1\". And for the following 270 rows, which is the data from Physics, add in a label \"2\".\n",
    "#For the last 222 rows, which is the data from Computer Science, add in a label \"3\".\n",
    "#Then, to merge the three datasets (History + Physics + Computer Science) to get the final dataset.\n",
    "smalltest = pd.read_csv(\"allword.csv\") #Import the dataset.\n",
    "smalltest = smalltest.drop('Unnamed: 0', axis = 1)\n",
    "smalltest = smalltest.iloc[:, :200]\n",
    "smalltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63df0c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research</th>\n",
       "      <th>engineering</th>\n",
       "      <th>studies</th>\n",
       "      <th>science</th>\n",
       "      <th>film</th>\n",
       "      <th>seluanov</th>\n",
       "      <th>gorbunova</th>\n",
       "      <th>spin</th>\n",
       "      <th>journal</th>\n",
       "      <th>literature</th>\n",
       "      <th>...</th>\n",
       "      <th>prize</th>\n",
       "      <th>area</th>\n",
       "      <th>feedback</th>\n",
       "      <th>processes</th>\n",
       "      <th>huo</th>\n",
       "      <th>lett</th>\n",
       "      <th>ocean</th>\n",
       "      <th>mitchell</th>\n",
       "      <th>mitra</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133825</td>\n",
       "      <td>6.091850</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.703516</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.141654</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.453708</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.036506</td>\n",
       "      <td>6.886457</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.126570</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.549105</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.429008</td>\n",
       "      <td>2.265932</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.517546</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.76942</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814299</td>\n",
       "      <td>5.963042</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>6.416940</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.787349</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>8.066240</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.030624</td>\n",
       "      <td>33.120246</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.043467</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2.486010</td>\n",
       "      <td>-0.050947</td>\n",
       "      <td>6.509896</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>11.661846</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6.988950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>-0.015155</td>\n",
       "      <td>-0.008282</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.906729</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.226845</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>-0.015159</td>\n",
       "      <td>-0.008294</td>\n",
       "      <td>5.454643</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.922337</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.940224</td>\n",
       "      <td>90.434222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>-0.084800</td>\n",
       "      <td>-0.046450</td>\n",
       "      <td>5.140450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>19.785706</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.402575</td>\n",
       "      <td>1.435222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>3.732752</td>\n",
       "      <td>-0.012862</td>\n",
       "      <td>5.847669</td>\n",
       "      <td>1.487289</td>\n",
       "      <td>9.352954</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.530372</td>\n",
       "      <td>95.544805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     research  engineering   studies   science       film  seluanov  \\\n",
       "0    0.133825     6.091850 -0.000000  0.083916   1.703516      -0.0   \n",
       "1   -0.036506     6.886457 -0.000000 -0.126570  -0.000000      -0.0   \n",
       "2    2.429008     2.265932 -0.000000 -0.000000   0.517546      -0.0   \n",
       "3   -0.814299     5.963042 -0.000000 -0.000000  -0.000000      -0.0   \n",
       "4   -1.030624    33.120246 -0.000000 -0.000000  -0.000000      -0.0   \n",
       "..        ...          ...       ...       ...        ...       ...   \n",
       "617  2.486010    -0.050947  6.509896 -0.000000  11.661846      -0.0   \n",
       "618 -0.015155    -0.008282 -0.000000 -0.000000   1.906729      -0.0   \n",
       "619 -0.015159    -0.008294  5.454643 -0.000000   1.922337      -0.0   \n",
       "620 -0.084800    -0.046450  5.140450 -0.000000  19.785706      -0.0   \n",
       "621  3.732752    -0.012862  5.847669  1.487289   9.352954      -0.0   \n",
       "\n",
       "     gorbunova  spin   journal  literature  ...  prize      area  feedback  \\\n",
       "0         -0.0  -0.0  0.141654   -0.000000  ...   -0.0 -0.000000 -0.000000   \n",
       "1         -0.0  -0.0  3.549105   -0.000000  ...   -0.0 -0.000000 -0.000000   \n",
       "2         -0.0  -0.0 -0.000000   -0.000000  ...   -0.0 -0.000000 -0.000000   \n",
       "3         -0.0  -0.0  6.416940   -0.000000  ...   -0.0  0.787349 -0.000000   \n",
       "4         -0.0  -0.0  3.043467   -0.000000  ...   -0.0 -0.000000 -0.000000   \n",
       "..         ...   ...       ...         ...  ...    ...       ...       ...   \n",
       "617       -0.0  -0.0 -0.000000    6.988950  ...   -0.0 -0.000000 -0.000000   \n",
       "618       -0.0  -0.0 -0.000000   -0.000000  ...   -0.0 -0.000000  0.226845   \n",
       "619       -0.0  -0.0  1.940224   90.434222  ...   -0.0 -0.000000 -0.000000   \n",
       "620       -0.0  -0.0  1.402575    1.435222  ...   -0.0 -0.000000 -0.000000   \n",
       "621       -0.0  -0.0  1.530372   95.544805  ...   -0.0 -0.000000 -0.000000   \n",
       "\n",
       "     processes  huo     lett  ocean  mitchell  mitra  output  \n",
       "0     0.453708 -0.0 -0.00000   -0.0  0.008231   -0.0       1  \n",
       "1    -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0       1  \n",
       "2    -0.000000 -0.0  0.76942   -0.0 -0.000000   -0.0       1  \n",
       "3     8.066240 -0.0 -0.00000   -0.0 -0.000000   -0.0       1  \n",
       "4    -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0       1  \n",
       "..         ...  ...      ...    ...       ...    ...     ...  \n",
       "617  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0      24  \n",
       "618  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0      24  \n",
       "619  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0      24  \n",
       "620  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0      24  \n",
       "621  -0.000000 -0.0 -0.00000   -0.0 -0.000000   -0.0      24  \n",
       "\n",
       "[622 rows x 201 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = smalltest.iloc[0:21] #Get the first 118 rows (data for History)\n",
    "filt['output'] = [1 for row in range(len(filt))] #Add in a label \"1\" for the first 118 rows\n",
    "filt2 = smalltest.iloc[21:70] #Get the next 270 rows (data for Physics)\n",
    "filt2['output'] = [2 for row in range(len(filt2))] #Add in a label \"2\" for the next 270 rows\n",
    "filt3 = smalltest.iloc[70:89] #Get the last 222 rows (data for Computer Science)\n",
    "filt3['output'] = [3 for row in range(len(filt3))] #Add in a label \"3\" for the last 222 rows\n",
    "filt4 = smalltest.iloc[89:129] #Get the last 222 rows (data for Computer Science)\n",
    "filt4['output'] = [4 for row in range(len(filt4))] #Add in a label \"3\" for the last 222 rows\n",
    "filt5 = smalltest.iloc[129:202] #Get the last 222 rows (data for Computer Science)\n",
    "filt5['output'] = [5 for row in range(len(filt5))] #Add in a label \"3\" for the last 222 rows\n",
    "filt6 = smalltest.iloc[202:209] #Get the last 222 rows (data for Computer Science)\n",
    "filt6['output'] = [6 for row in range(len(filt6))] #Add in a label \"3\" for the last 222 rows\n",
    "filt7 = smalltest.iloc[209:240] #Get the last 222 rows (data for Computer Science)\n",
    "filt7['output'] = [7 for row in range(len(filt7))] #Add in a label \"3\" for the last 222 rows\n",
    "filt8 = smalltest.iloc[240:271] #Get the last 222 rows (data for Computer Science)\n",
    "filt8['output'] = [8 for row in range(len(filt8))] #Add in a label \"3\" for the last 222 rows\n",
    "filt9 = smalltest.iloc[271:301] #Get the last 222 rows (data for Computer Science)\n",
    "filt9['output'] = [9 for row in range(len(filt9))] #Add in a label \"3\" for the last 222 rows\n",
    "filt10 = smalltest.iloc[301:318] #Get the last 222 rows (data for Computer Science)\n",
    "filt10['output'] = [10 for row in range(len(filt10))] #Add in a label \"3\" for the last 222 rows\n",
    "filt11 = smalltest.iloc[318:337] #Get the last 222 rows (data for Computer Science)\n",
    "filt11['output'] = [11 for row in range(len(filt11))] #Add in a label \"3\" for the last 222 rows\n",
    "filt12 = smalltest.iloc[337:348] #Get the last 222 rows (data for Computer Science)\n",
    "filt12['output'] = [12 for row in range(len(filt12))] #Add in a label \"3\" for the last 222 rows\n",
    "filt13 = smalltest.iloc[348:393] #Get the last 222 rows (data for Computer Science)\n",
    "filt13['output'] = [13 for row in range(len(filt13))] #Add in a label \"3\" for the last 222 rows\n",
    "filt14 = smalltest.iloc[393:415] #Get the last 222 rows (data for Computer Science)\n",
    "filt14['output'] = [14 for row in range(len(filt14))] #Add in a label \"3\" for the last 222 rows\n",
    "filt15 = smalltest.iloc[415:430] #Get the last 222 rows (data for Computer Science)\n",
    "filt15['output'] = [15 for row in range(len(filt15))] #Add in a label \"3\" for the last 222 rows\n",
    "filt16 = smalltest.iloc[430:447] #Get the last 222 rows (data for Computer Science)\n",
    "filt16['output'] = [16 for row in range(len(filt16))] #Add in a label \"3\" for the last 222 rows\n",
    "filt17 = smalltest.iloc[447:465] #Get the last 222 rows (data for Computer Science)\n",
    "filt17['output'] = [17 for row in range(len(filt17))] #Add in a label \"3\" for the last 222 rows\n",
    "filt18 = smalltest.iloc[465:485] #Get the last 222 rows (data for Computer Science)\n",
    "filt18['output'] = [18 for row in range(len(filt18))] #Add in a label \"3\" for the last 222 rows\n",
    "filt19 = smalltest.iloc[485:503] #Get the last 222 rows (data for Computer Science)\n",
    "filt19['output'] = [19 for row in range(len(filt19))] #Add in a label \"3\" for the last 222 rows\n",
    "filt20 = smalltest.iloc[503:520] #Get the last 222 rows (data for Computer Science)\n",
    "filt20['output'] = [20 for row in range(len(filt20))]\n",
    "filt21 = smalltest.iloc[520:530] #Get the last 222 rows (data for Computer Science)\n",
    "filt21['output'] = [21 for row in range(len(filt21))]\n",
    "filt22 = smalltest.iloc[530:568] #Get the last 222 rows (data for Computer Science)\n",
    "filt22['output'] = [22 for row in range(len(filt22))]\n",
    "filt23 = smalltest.iloc[568:583] #Get the last 222 rows (data for Computer Science)\n",
    "filt23['output'] = [23 for row in range(len(filt23))]\n",
    "filt24 = smalltest.iloc[583:622] #Get the last 222 rows (data for Computer Science)\n",
    "filt24['output'] = [24 for row in range(len(filt24))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "smalltest = pd.merge(filt, filt2, how = 'outer') #Merge the three datasets for History, Physics, and Computer Science\n",
    "smalltest = pd.merge(smalltest, filt3, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt4, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt5, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt6, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt7, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt8, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt9, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt10, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt11, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt12, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt13, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt14, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt15, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt16, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt17, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt18, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt19, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt20, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt21, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt22, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt23, how = 'outer')\n",
    "smalltest = pd.merge(smalltest, filt24, how = 'outer')\n",
    "\n",
    "smalltest\n",
    "#smalltest.to_csv('smalltest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3797d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the part to separate training set and testing set. I would pick a size of 15 as testing set, which includes\n",
    "#5 data from History, 5 data from Physics, and 5 data from Computer Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24d075ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5496666666666666\n",
      "      CE   CS  HIS   ME  PHY  ANT  BIO  ECON  ENG  PHIL  ...  REL  ARTH  DANC  \\\n",
      "CE    34    3    4   21    4    0    0     0    0     0  ...    0     0     0   \n",
      "CS     0  183    0    1    7    0    2     0    0     0  ...    0     0     0   \n",
      "HIS    0    0   58    0    5    0    0     0    3     0  ...    0    25     0   \n",
      "ME    25    3    0  107   36    0    5     0    0     1  ...    0     0     0   \n",
      "PHY    5    9    0   17  261    0    9     6    0     0  ...    0     0     4   \n",
      "ANT    0    0    0    0    8    8   10     0    0     0  ...    0    17     0   \n",
      "BIO    9    0    0    3    3    0   88    31    0     0  ...    0     0     0   \n",
      "ECON   0    0    0    0    0    0    0   124    0     0  ...    0     0     0   \n",
      "ENG    0    5    1    0    9    0    1    28   51     8  ...   12    25     5   \n",
      "PHIL   0    4    0    1    0    0    3     6    0    50  ...    5     7     8   \n",
      "BCS    0   20    0    0    0    0   13    12    0     0  ...    2     0     0   \n",
      "LIN    0    6    0    0    0    0    3     7    5    12  ...    3     0     0   \n",
      "OPT    0    0    1   13   17    0    4     0    0     0  ...    0     0     0   \n",
      "PSY    0    2    0    0    9    3   32    11    0     0  ...    1     0     0   \n",
      "REL    0    0    0    0    0    0    7    44    1     0  ...    2     2     0   \n",
      "ARTH   0    0   17    0    0   11    0     7   15     0  ...    4     0    13   \n",
      "DANC   0    0    0    0    5    0    0     4    0     3  ...    4    15    31   \n",
      "EES    0    0    0    0    1    0    0    36    0     0  ...    0     0    10   \n",
      "MUSC   0    6    0    0    4    0    8     6    0     0  ...    2     0     0   \n",
      "AAS    0    0    0    0    0    0    0     4    1     0  ...   17     8    10   \n",
      "AME    0    0    0    0    0    0    0     5    0     0  ...    0     0     0   \n",
      "ECE    1   34    0   12    7    0    9     2    0     0  ...    0     0     0   \n",
      "FMS    0    0    0    0    0    0    0     8    0     0  ...    0     4     6   \n",
      "MLC    0    0    0    0    0    1    5     0    0     0  ...    0     9     0   \n",
      "\n",
      "      EES  MUSC  AAS  AME  ECE  FMS  MLC  \n",
      "CE      0     0    0    0    3    0    0  \n",
      "CS      0     1    0    0   31    0    0  \n",
      "HIS     0     0    0    0    0    0    0  \n",
      "ME      0     0    0    0    5    0    0  \n",
      "PHY     0    16    1    3   14    0    0  \n",
      "ANT     0     0    0    0    0    0    0  \n",
      "BIO     0     0    0    0    0    0    0  \n",
      "ECON    0     0    6    0    0    0    0  \n",
      "ENG     3     0    0    0    0    5    6  \n",
      "PHIL    0     0    0    0    0    0    0  \n",
      "BCS     0     0    0    0   10    0    0  \n",
      "LIN     0     0    0    0    0    0    0  \n",
      "OPT     0     0    0    0   19    0    0  \n",
      "PSY     0     0    0    0    0    0    0  \n",
      "REL     0     0   11    0    0    0    0  \n",
      "ARTH    0     0    6    0    0    2    8  \n",
      "DANC   11     0   11    0    0    4    0  \n",
      "EES    54     0    3    0    0    0    4  \n",
      "MUSC    0    42    6    0    0    0    0  \n",
      "AAS    11     0   45    0    0    0    0  \n",
      "AME     0     0    0    2   42    0    0  \n",
      "ECE     0     0    0   39   53    0    0  \n",
      "FMS     0     0    0    0    0   57    4  \n",
      "MLC     0     0    0    0    0    0  109  \n",
      "\n",
      "[24 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "count = 0\n",
    "w, h = 24, 24\n",
    "#error = [[0 for x in range(w)] for y in range(h)] \n",
    "#accurate = [[0 for x in range(w)] for y in range(h)] \n",
    "result = [[0 for x in range(w)] for y in range(h)] \n",
    "for i in range(100):\n",
    "    smalltest_new = pd.merge(filt, filt2, how = 'outer') #Merge the three datasets for History, Physics, and Computer Science\n",
    "    smalltest_new = pd.merge(smalltest_new, filt3, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt4, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt5, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt6, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt7, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt8, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt9, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt10, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt11, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt12, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt13, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt14, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt15, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt16, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt17, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt18, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt19, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt20, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt21, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt22, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt23, how = 'outer')\n",
    "    smalltest_new = pd.merge(smalltest_new, filt24, how = 'outer')\n",
    "    \n",
    "    loc_1 = random.randint(0, 100)\n",
    "    loc_2 = random.randint(100, 200)\n",
    "    loc_3 = random.randint(200, 300)\n",
    "    loc_4 = random.randint(300, 400)\n",
    "    loc_5 = random.randint(400, 500)\n",
    "    loc_6 = random.randint(500, 600)\n",
    "    #print(\"loc_1: \", loc_1)\n",
    "    #print(\"loc_2: \", loc_2)\n",
    "    #print(\"loc_3: \", loc_3)\n",
    "\n",
    "    test_x = smalltest_new.iloc[[loc_1, loc_1+3, loc_1+6, loc_1+9, loc_1+12, loc_2, loc_2+3, loc_2+6, loc_2+9, loc_2+12, loc_3, loc_3+3, loc_3+6, loc_3+9, loc_3+12, loc_4, loc_4+3, loc_4+6, loc_4+9, loc_4+12, loc_5, loc_5+3, loc_5+6, loc_5+9, loc_5+12, loc_6, loc_6+3, loc_6+6, loc_6+9, loc_6+12], :]\n",
    "    train_x = smalltest_new.drop([loc_1, loc_1+3, loc_1+6, loc_1+9, loc_1+12, loc_2, loc_2+3, loc_2+6, loc_2+9, loc_2+12, loc_3, loc_3+3, loc_3+6, loc_3+9, loc_3+12, loc_4, loc_4+3, loc_4+6, loc_4+9, loc_4+12, loc_5, loc_5+3, loc_5+6, loc_5+9, loc_5+12, loc_6, loc_6+3, loc_6+6, loc_6+9, loc_6+12])\n",
    "    test_y = np.array(test_x['output'])\n",
    "    test_x = test_x.drop('output', axis = 1)\n",
    "    train_y = np.array(train_x['output'])\n",
    "    train_x = train_x.drop('output', axis = 1)\n",
    "    #print(test_y)\n",
    "    \n",
    "    lin = svm.SVC(kernel = 'rbf', C = 100)\n",
    "    lin.fit(train_x, train_y)\n",
    "    predict = lin.predict(test_x)\n",
    "    #print(predict)\n",
    "    #print(confusion_matrix(test_y, predict))\n",
    "    \n",
    "    for i in range(len(test_y)):\n",
    "        result[test_y[i] - 1][predict[i] - 1] += 1\n",
    "        \n",
    "    \n",
    "    #knn = neighbors.KNeighborsRegressor(14, weights=\"uniform\")\n",
    "    #knn.fit(np.array(train_x), np.array(train_y))\n",
    "    #predict = knn.predict(test_x)\n",
    "    \n",
    "    acc_num = sum(predict == test_y)\n",
    "    answer.append(acc_num)\n",
    "\n",
    "accuracy = np.average(answer)\n",
    "\n",
    "print(\"accuracy:\", accuracy/30)\n",
    "#print(np.asmatrix(error))\n",
    "\n",
    "result_new = pd.DataFrame(result)\n",
    "#accurate_new = pd.DataFrame(accurate)\n",
    "result_new.index = ['CE', 'CS', 'HIS', 'ME', 'PHY', 'ANT', 'BIO', 'ECON', 'ENG', 'PHIL', 'BCS', 'LIN', 'OPT', 'PSY', 'REL', 'ARTH', 'DANC', 'EES', 'MUSC', 'AAS', 'AME', 'ECE', 'FMS', 'MLC']\n",
    "result_new.columns = ['CE', 'CS', 'HIS', 'ME', 'PHY', 'ANT', 'BIO', 'ECON', 'ENG', 'PHIL', 'BCS', 'LIN', 'OPT', 'PSY', 'REL', 'ARTH', 'DANC', 'EES', 'MUSC', 'AAS', 'AME', 'ECE', 'FMS', 'MLC']\n",
    "#accurate_new.index = ['CE', 'CS', 'HIS', 'ME', 'PHY', 'ANT', 'BIO', 'ECON', 'ENG', 'PHIL', 'BCS', 'LIN', 'OPT', 'PSY', 'REL', 'ARTH', 'DANC', 'EES', 'MUSC', 'AAS', 'AME', 'ECE', 'FMS', 'MLC']\n",
    "#accurate_new.columns = ['CE', 'CS', 'HIS', 'ME', 'PHY', 'ANT', 'BIO', 'ECON', 'ENG', 'PHIL', 'BCS', 'LIN', 'OPT', 'PSY', 'REL', 'ARTH', 'DANC', 'EES', 'MUSC', 'AAS', 'AME', 'ECE', 'FMS', 'MLC']\n",
    "\n",
    "print(result_new)\n",
    "#print(accurate_new)\n",
    "\n",
    "result_new.to_csv('result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aea6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc_1:  59\n",
      "loc_2:  431\n",
      "loc_3:  555\n"
     ]
    }
   ],
   "source": [
    "loc_1 = random.randint(0, 160)\n",
    "loc_2 = random.randint(170, 440)\n",
    "loc_3 = random.randint(450,750)\n",
    "print(\"loc_1: \", loc_1)\n",
    "print(\"loc_2: \", loc_2)\n",
    "print(\"loc_3: \", loc_3)\n",
    "\n",
    "test_x = smalltest.iloc[[loc_1, loc_1+3, loc_1+6, loc_1+9, loc_1+12, loc_2, loc_2+3, loc_2+6, loc_2+9, loc_2+12, loc_3, loc_3+3, loc_3+6, loc_3+9, loc_3+12], :]\n",
    "train_x = smalltest.drop([loc_1, loc_1+3, loc_1+6, loc_1+9, loc_1+12, loc_2, loc_2+3, loc_2+6, loc_2+9, loc_2+12, loc_3, loc_3+3, loc_3+6, loc_3+9, loc_3+12])\n",
    "test_y = np.array(test_x['output'])\n",
    "test_x = test_x.drop('output', axis = 1)\n",
    "train_y = np.array(train_x['output'])\n",
    "train_x = train_x.drop('output', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "497f4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#testing set\\ntest_x_1 = smalltest.iloc[113:118] #I would directly pick row 21 to row 25 a testing set 1.\\ntest_x_2 = smalltest.iloc[383:393] #I would directly pick row 140 to row 149 as testing set 2\\ntest_x = pd.merge(test_x_1, test_x_2, how = 'outer')\\ntest_y = np.array(test_x['output'])\\ntest_x = test_x.drop('output', axis = 1)\\ntest_x = np.array(test_x)\\n#training set\\ntrain_x_1 = smalltest.iloc[0:113] #The training set would then be row 0-20, row 26-139, and row 150-215. Merge then to get the training set.\\ntrain_x_2 = smalltest.iloc[118:383]\\ntrain_x_3 = smalltest.iloc[393:610]\\ntrain_x = pd.merge(train_x_1, train_x_2, how = 'outer')\\ntrain_x = pd.merge(train_x, train_x_3, how = 'outer')\\ntrain_y = np.array(train_x['output'])\\ntrain_x = train_x.drop('output', axis = 1)\\ntrain_x = np.array(train_x)\\ntrain_y = np.array(train_y)\\n\""
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#testing set\n",
    "test_x_1 = smalltest.iloc[113:118] #I would directly pick row 21 to row 25 a testing set 1.\n",
    "test_x_2 = smalltest.iloc[383:393] #I would directly pick row 140 to row 149 as testing set 2\n",
    "test_x = pd.merge(test_x_1, test_x_2, how = 'outer')\n",
    "test_y = np.array(test_x['output'])\n",
    "test_x = test_x.drop('output', axis = 1)\n",
    "test_x = np.array(test_x)\n",
    "#training set\n",
    "train_x_1 = smalltest.iloc[0:113] #The training set would then be row 0-20, row 26-139, and row 150-215. Merge then to get the training set.\n",
    "train_x_2 = smalltest.iloc[118:383]\n",
    "train_x_3 = smalltest.iloc[393:610]\n",
    "train_x = pd.merge(train_x_1, train_x_2, how = 'outer')\n",
    "train_x = pd.merge(train_x, train_x_3, how = 'outer')\n",
    "train_y = np.array(train_x['output'])\n",
    "train_x = train_x.drop('output', axis = 1)\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eebab0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d6f26c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the part for SVM. We used the function .SVC directly since it's convenient and powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "89b9426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d15cdb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For kernel function, we just pick \"linear\". We found out that the accuracy of linear function is already 100%,\n",
    "#and we don't think we need to make the model more complicated by choosing another kernel function while linear function \n",
    "#can already work really well. For C, we just pick 100. We tried to test different C, like 0.01, 1, 100, 10000, but \n",
    "#there isn't much difference in the result. Therefore, we just picked 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c7d6c606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = svm.SVC(kernel = 'rbf', C = 100)\n",
    "lin.fit(train_x, train_y)\n",
    "predict = lin.predict(test_x)\n",
    "acc_num = sum(predict == test_y)\n",
    "acc_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "18d4bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the part to show final result. Predict shows the array of predicted result. \n",
    "#Accuracy show the percentage of accuracy.\n",
    "#confusion_matrix would draw a confusion matrix which represents our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f2871f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: [2 1 1 1 1 2 2 2 2 2 2 3 2 2 3]\n",
      "Accuracy: 0.7333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 0],\n",
       "       [0, 5, 0],\n",
       "       [0, 3, 2]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predict:\", predict)\n",
    "print(\"Accuracy:\" , acc_num/15)\n",
    "confusion_matrix(test_y, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17ac4ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/runzhouliu/Desktop/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /Users/runzhouliu/Desktop/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (737,) for Tensor 'Placeholder_1:0', which has shape '(?, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ad44b6bade1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 迭代\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1162\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[1;32m   1163\u001b[0m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[0;32m-> 1164\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1165\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (737,) for Tensor 'Placeholder_1:0', which has shape '(?, 3)'"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 20])\n",
    "\n",
    "W = tf.Variable(tf.zeros([20, 3]))\n",
    "\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y + 1e-10))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# 初始化\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 迭代\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={x: train_x, y_: train_y})\n",
    "    if i % 50 == 0:\n",
    "        correct_prediction = tf.equal(test_x, test_y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d847bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 737 samples\n",
      "Epoch 1/8\n",
      "737/737 [==============================] - 0s 86us/sample - loss: 8.4207 - acc: 0.0027\n",
      "Epoch 2/8\n",
      "737/737 [==============================] - 0s 6us/sample - loss: 4.5146 - acc: 0.0556\n",
      "Epoch 3/8\n",
      "737/737 [==============================] - 0s 6us/sample - loss: 2.7123 - acc: 0.2768\n",
      "Epoch 4/8\n",
      "737/737 [==============================] - 0s 5us/sample - loss: 1.9477 - acc: 0.5360\n",
      "Epoch 5/8\n",
      "737/737 [==============================] - 0s 7us/sample - loss: 1.6097 - acc: 0.7436\n",
      "Epoch 6/8\n",
      "737/737 [==============================] - 0s 5us/sample - loss: 1.4329 - acc: 0.7680\n",
      "Epoch 7/8\n",
      "737/737 [==============================] - 0s 6us/sample - loss: 1.3097 - acc: 0.8060\n",
      "Epoch 8/8\n",
      "737/737 [==============================] - 0s 7us/sample - loss: 1.2188 - acc: 0.8277\n",
      "[1.2273503541946411, 0.73333335]\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(20,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history =  model.fit(train_x,\n",
    "                  train_y,\n",
    "                  epochs=8,\n",
    "                  batch_size=512)\n",
    "results = model.evaluate(test_x,test_y)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131c142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c09d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
